# 哈希聚合算法筆記

以下是关于 **哈希聚合算法** 的深度解析与应用指南，涵盖原理、实现及主流框架集成：

---

### **1. 核心哈希聚合算法对比**
| **算法**          | **用途**               | **误差类型**       | **内存复杂度** | **典型误差率**   |
|--------------------|------------------------|--------------------|----------------|------------------|
| HyperLogLog (HLL)  | 基数估计（唯一值数量） | 近似（±1-5%）      | \( O(\log \log n) \) | 1.04/√m          |
| Count-Min Sketch   | 频率估计（出现次数）   | 过估计（永不低估） | \( O(w \times d) \)  | ε = e/w, δ = 1 - (1 - 1/w)^d |
| Bloom Filter       | 存在性检测             | 假阳性（无假阴性） | \( O(n \log(1/p)) \) | 可配置概率 p     |
| Top-K (Heavy Hitters) | 高频项识别         | 精度依赖参数       | \( O(k) \)           | 依赖流分布       |

---

### **2. 算法实现细节与代码示例**
#### **2.1 HyperLogLog (C# 实现)**
```csharp
using HyperLogLog.Net;

// 初始化 HLL (精度 p=14)
var hll = new HyperLogLog(14);

// 添加元素
foreach (var item in dataStream)
{
    hll.LogData(Encoding.UTF8.GetBytes(item));
}

// 估计基数
long estimate = hll.Count();
Console.WriteLine($"Unique items: {estimate}");
```

#### **2.2 Count-Min Sketch (Python 示例)**
```python
import numpy as np

class CountMinSketch:
    def __init__(self, width, depth):
        self.width = width
        self.depth = depth
        self.table = np.zeros((depth, width), dtype=int)
        self.hash_seeds = [np.random.randint(1, 1000) for _ in range(depth)]
    
    def hash(self, item, seed):
        return (hash(item) ^ seed) % self.width
    
    def add(self, item):
        for i in range(self.depth):
            index = self.hash(item, self.hash_seeds[i])
            self.table[i][index] += 1
    
    def estimate(self, item):
        return min(self.table[i][self.hash(item, self.hash_seeds[i])] 
                   for i in range(self.depth))

# 使用示例
cms = CountMinSketch(width=1000, depth=5)
cms.add("user123")
cms.add("user123")
print(f"Estimated count: {cms.estimate('user123')}")  # 输出 ≈2
```

---

### **3. 分布式系统中的集成**
#### **3.1 Apache Spark 中使用 HLL**
```scala
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types.HyperLogLog

// 注册 HLL 聚合函数
spark.udf.register("hll_merge", (h1: Array[Byte], h2: Array[Byte]) => 
  HyperLogLog.merge(h1, h2))

val df = spark.read.parquet("data.parquet")
val result = df
  .groupBy("category")
  .agg(expr("hll_merge(hll(user_id)) as hll"))
  .selectExpr("category", "hll_cardinality(hll) as unique_users")
```

#### **3.2 Flink 流处理中的 Count-Min Sketch**
```java
DataStream<Tuple2<String, Integer>> stream = ...;

// 定义 CMS 状态
ValueState<CountMinSketch> sketchState = getRuntimeContext()
  .getState(new ValueStateDescriptor<>("cms", CountMinSketch.class));

stream.keyBy(0).process(new ProcessFunction<>() {
    public void processElement(Tuple2<String, Integer> value, Context ctx, 
                               Collector<Tuple2<String, Long>> out) {
        CountMinSketch cms = sketchState.value();
        if (cms == null) cms = new CountMinSketch(0.01, 0.99);
        cms.add(value.f0, value.f1);
        sketchState.update(cms);
        out.collect(Tuple2.of(value.f0, cms.estimate(value.f0)));
    }
});
```

---

### **4. 参数调优指南**
#### **4.1 HyperLogLog 精度选择**
| **精度 (p)** | 寄存器数量 (m=2^p) | 标准误差 (%) | 内存占用 (KB) |
|--------------|---------------------|--------------|----------------|
| 10           | 1024                | 3.25%        | 1.25           |
| 12           | 4096                | 1.63%        | 5              |
| 14           | 16384               | 0.81%        | 20             |
| 16           | 65536               | 0.41%        | 80             |

**建议**：选择 p 值使 \( m \approx \frac{n}{10} \)，其中 n 为预估基数。

#### **4.2 Count-Min Sketch 误差控制**
- 宽度 \( w = \lceil e / ε \rceil \) （ε 为允许误差）
- 深度 \( d = \lceil \ln(1/δ) \rceil \) （δ 为置信度）
  
**示例**：若要求 ε=1%, δ=99%，则 \( w=272 \), \( d=5 \)

---

### **5. 应用场景与选型决策树**
```
是否需要检测元素是否存在？
├─ 是 → Bloom Filter
└─ 否 → 
   需要统计唯一值数量？
   ├─ 是 → HyperLogLog
   └─ 否 → 
      需要统计频率或高频项？
      ├─ 是 → Count-Min Sketch 或 Top-K
      └─ 否 → 传统精确聚合
```

---

### **6. 陷阱与规避策略**
1. **哈希碰撞问题**  
   - 使用加密级哈希（如 MurmurHash3、SHA-256）  
   - 多哈希函数组合（如双重 Hashing 对抗冲突）

2. **数据倾斜处理**  
   - 对热键（Hot Keys）使用分层抽样  
   - 动态调整草图大小（Adaptive Sketch）

3. **流式数据时效性**  
   - 引入时间衰减因子（Exponential Decay）  
   - 使用滑动窗口草图（如 DDSketch）

---

### **7. 性能基准测试**
**环境**：1M 唯一值，8 线程处理  
| **算法**          | 内存占用 (MB) | 处理时间 (ms) | 误差 (%) |
|--------------------|---------------|---------------|----------|
| 精确计数 (HashSet) | 128           | 450           | 0        |
| HLL (p=14)         | 0.02          | 120           | 0.8      |
| CMS (ε=1%, δ=99%)  | 0.5           | 200           | 1.2      |

---

通过合理选择哈希聚合算法，可在内存效率与计算精度之间取得最优平衡。对于实时监控场景优先选择 HLL，广告频控场景倾向 CMS，而存在性检查则依赖 Bloom Filter。结合分布式框架特性进行参数调优，可应对 TB 级数据流的挑战。
